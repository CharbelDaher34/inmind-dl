{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detect import detect_objects\n",
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n",
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n",
      "IDetect.fuse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charbel/.local/lib/python3.11/site-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "output, ptTime = detect_objects(\n",
    "    \"../bestModels/yolo.pt\",\n",
    "    \"../data/rgb_0999.png\",\n",
    "    conf_thres=0.35,\n",
    "    iou_thres=0.45,\n",
    "    img_size=640,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yoloInference(image_path, model_path):\n",
    "    # Load the ONNX model\n",
    "    session = ort.InferenceSession(model_path)\n",
    "    image = Image.open(image_path)\n",
    "    image_tensor = torch.tensor(\n",
    "        np.expand_dims(np.array(image)[:, :, :3], axis=0), dtype=torch.float32\n",
    "    )  # Add batch dimension\n",
    "    image_tensor = image_tensor.permute(0, 3, 1, 2)\n",
    "\n",
    "    resize = transforms.Resize((640, 640))  # Define resize transformation\n",
    "    image_tensor = resize(image_tensor)\n",
    "\n",
    "    # Perform inference\n",
    "    input_name = session.get_inputs()[0].name\n",
    "    start_time = time.time()  # Capture end time\n",
    "    outputs = session.run(None, {input_name: np.array(image_tensor)})\n",
    "    end_time = time.time()  # Capture end time\n",
    "    return outputs, end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs, onnxTime = yoloInference(\"../data/rgb_0999.png\", \"../bestModels/yolo.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX Inference Time: 1.2213 seconds\n",
      "PT Inference Time: 1.0035 seconds\n"
     ]
    }
   ],
   "source": [
    "print(f\"ONNX Inference Time: {onnxTime:.4f} seconds\")\n",
    "print(f\"PT Inference Time: {ptTime:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "\n",
    "def yoloInferenceLive(model_path):\n",
    "    # Load the ONNX model\n",
    "    session = ort.InferenceSession(model_path)\n",
    "\n",
    "    # Open the webcam capture (0 is the default webcam)\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Convert frame to PIL Image\n",
    "        image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "        image_tensor = torch.tensor(\n",
    "            np.expand_dims(np.array(image)[:, :, :3], axis=0), dtype=torch.float32\n",
    "        )  # Add batch dimension\n",
    "        image_tensor = image_tensor.permute(0, 3, 1, 2)\n",
    "\n",
    "        resize = transforms.Resize((640, 640))  # Define resize transformation\n",
    "        image_tensor = resize(image_tensor)\n",
    "\n",
    "        # Perform inference\n",
    "        input_name = session.get_inputs()[0].name\n",
    "        start_time = time.time()  # Capture start time\n",
    "        outputs = session.run(None, {input_name: np.array(image_tensor)})\n",
    "        end_time = time.time()  # Capture end time\n",
    "\n",
    "        # Process outputs (e.g., draw bounding boxes on the frame)\n",
    "        # This part depends on the specific output format of your model\n",
    "        # For now, we'll just print the inference time\n",
    "        print(f\"Inference Time: {end_time - start_time:.4f} seconds\")\n",
    "\n",
    "        # Display the frame\n",
    "        cv2.imshow(\"YOLO Inference\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yoloInferenceLive(\"../bestModels/yolo.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inmindProjectEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
