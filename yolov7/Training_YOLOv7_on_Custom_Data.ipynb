{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.26.4\n"
          ]
        }
      ],
      "source": [
        "print(np.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nD-uPyQ_2jiN"
      },
      "outputs": [],
      "source": [
        "# Download YOLOv7 repository and install requirements\n",
        "!git clone https://github.com/WongKinYiu/yolov7\n",
        "%cd yolov7\n",
        "%pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/charbel/Desktop/stages/inmind.ai/material/week4-computervision/mywork/yolov7/yolov7\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/charbel/.local/lib/python3.11/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
            "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
          ]
        }
      ],
      "source": [
        "%cd yolov7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mcfg\u001b[0m/       \u001b[01;34mfigure\u001b[0m/     \u001b[01;34mpaper\u001b[0m/            \u001b[01;34mscripts\u001b[0m/      \u001b[01;34mutils\u001b[0m/\n",
            "\u001b[01;34mdata\u001b[0m/      hubconf.py  \u001b[01;34m__pycache__\u001b[0m/      test.py       yolov7_training.pt\n",
            "\u001b[01;34mdeploy\u001b[0m/    \u001b[01;34minference\u001b[0m/  README.md         \u001b[01;34mtools\u001b[0m/\n",
            "detect.py  LICENSE.md  requirements.txt  train_aux.py\n",
            "export.py  \u001b[01;34mmodels\u001b[0m/     \u001b[01;34mruns\u001b[0m/             train.py\n"
          ]
        }
      ],
      "source": [
        "%ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "bUbmy674bhpD"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-08-12 15:15:11--  https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7_training.pt\n",
            "Resolving github.com (github.com)... 140.82.121.3\n",
            "Connecting to github.com (github.com)|140.82.121.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/511187726/13e046d1-f7f0-43ab-910b-480613181b1f?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20240812%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240812T121512Z&X-Amz-Expires=300&X-Amz-Signature=1bed22c28bcd15cb670d5dbcfcf411533778c75e2a8a7cb718751e8940c055d4&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=511187726&response-content-disposition=attachment%3B%20filename%3Dyolov7_training.pt&response-content-type=application%2Foctet-stream [following]\n",
            "--2024-08-12 15:15:12--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/511187726/13e046d1-f7f0-43ab-910b-480613181b1f?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20240812%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240812T121512Z&X-Amz-Expires=300&X-Amz-Signature=1bed22c28bcd15cb670d5dbcfcf411533778c75e2a8a7cb718751e8940c055d4&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=511187726&response-content-disposition=attachment%3B%20filename%3Dyolov7_training.pt&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 75628875 (72M) [application/octet-stream]\n",
            "Saving to: â€˜yolov7_training.pt.2â€™\n",
            "\n",
            "yolov7_training.pt.   0%[                    ]       0  --.-KB/s               ^C\n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7_training.pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "1iqOPKjr22mL"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-08-12 17:31:34.018376: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-08-12 17:31:34.208774: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-08-12 17:31:34.256590: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-08-12 17:31:34.582123: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-08-12 17:31:36.508186: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "YOLOR ðŸš€ v0.1-128-ga207844 torch 2.3.1+cu121 CPU\n",
            "\n",
            "Namespace(weights='yolov7_training.pt', cfg='cfg/training/yolov7x.yaml', data='./data/data.yaml', hyp='data/hyp.scratch.p5.yaml', epochs=5, batch_size=16, img_size=[1280, 720], rect=False, resume=False, nosave=False, notest=False, noautoanchor=False, evolve=False, bucket='', cache_images=False, image_weights=False, device='', multi_scale=False, single_cls=False, adam=False, sync_bn=False, local_rank=-1, workers=8, project='runs/train', entity=None, name='yolov7', exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, upload_dataset=False, bbox_interval=-1, save_period=-1, artifact_alias='latest', freeze=[0], v5_metric=False, world_size=1, global_rank=-1, save_dir='runs/train/yolov7', total_batch_size=16)\n",
            "\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.3, cls_pw=1.0, obj=0.7, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.2, scale=0.9, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.15, copy_paste=0.0, paste_in=0.15, loss_ota=1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: ^C\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/charbel/Desktop/stages/inmind.ai/material/week4-computervision/mywork/yolov7/yolov7/train.py\", line 616, in <module>\n",
            "    train(hyp, opt, device, tb_writer)\n",
            "  File \"/home/charbel/Desktop/stages/inmind.ai/material/week4-computervision/mywork/yolov7/yolov7/train.py\", line 72, in train\n",
            "    wandb_logger = WandbLogger(opt, Path(opt.save_dir).stem, run_id, data_dict)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/charbel/Desktop/stages/inmind.ai/material/week4-computervision/mywork/yolov7/yolov7/utils/wandb_logging/wandb_utils.py\", line 95, in __init__\n",
            "    self.wandb_run = wandb.init(config=opt,\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/charbel/anaconda3/envs/inmindProjectEnv/lib/python3.11/site-packages/wandb/sdk/wandb_init.py\", line 1176, in init\n",
            "    wi.setup(kwargs)\n",
            "  File \"/home/charbel/anaconda3/envs/inmindProjectEnv/lib/python3.11/site-packages/wandb/sdk/wandb_init.py\", line 292, in setup\n",
            "    wandb_login._login(\n",
            "  File \"/home/charbel/anaconda3/envs/inmindProjectEnv/lib/python3.11/site-packages/wandb/sdk/wandb_login.py\", line 346, in _login\n",
            "    wlogin.prompt_api_key()\n",
            "  File \"/home/charbel/anaconda3/envs/inmindProjectEnv/lib/python3.11/site-packages/wandb/sdk/wandb_login.py\", line 273, in prompt_api_key\n",
            "    key, status = self._prompt_api_key()\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/charbel/anaconda3/envs/inmindProjectEnv/lib/python3.11/site-packages/wandb/sdk/wandb_login.py\", line 252, in _prompt_api_key\n",
            "    key = apikey.prompt_api_key(\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/charbel/anaconda3/envs/inmindProjectEnv/lib/python3.11/site-packages/wandb/sdk/lib/apikey.py\", line 127, in prompt_api_key\n",
            "    result = prompt_choices(\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/home/charbel/anaconda3/envs/inmindProjectEnv/lib/python3.11/site-packages/wandb/util.py\", line 1268, in prompt_choices\n",
            "    choice = _prompt_choice(input_timeout=input_timeout, jupyter=jupyter)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/charbel/anaconda3/envs/inmindProjectEnv/lib/python3.11/site-packages/wandb/util.py\", line 1251, in _prompt_choice\n",
            "    choice = input_fn(text)\n",
            "             ^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n"
          ]
        }
      ],
      "source": [
        "!python train.py --batch 16 --epochs 5 --data ./data/data.yaml --weights 'yolov7_training.pt' --name yolov7 --img 1280 720 --cf cfg/training/yolov7x.yaml\n",
        "# !python train.py --batch 16 --epochs 1 --data ./data/data.yaml --weights 'yolov7_training.pt' --name yolov7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0W0MpUaTCJro"
      },
      "source": [
        "# Evaluation\n",
        "\n",
        "We can evaluate the performance of our custom training using the provided evalution script.\n",
        "\n",
        "Note we can adjust the below custom arguments. For details, see [the arguments accepted by detect.py](https://github.com/WongKinYiu/yolov7/blob/main/detect.py#L154)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "N4cfnLtTCIce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Namespace(weights=['runs/train/yolov7/weights/init.pt'], source='../yolov7_data/test/images/', img_size=640, conf_thres=0.1, iou_thres=0.45, device='', view_img=False, save_txt=False, save_conf=False, nosave=False, classes=None, agnostic_nms=False, augment=False, update=False, project='runs/detect', name='exp', exist_ok=False, no_trace=False)\n",
            "YOLOR ðŸš€ v0.1-128-ga207844 torch 2.3.1+cu121 CPU\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/charbel/Desktop/stages/inmind.ai/material/week4-computervision/mywork/yolov7/yolov7/detect.py\", line 196, in <module>\n",
            "    detect()\n",
            "  File \"/home/charbel/Desktop/stages/inmind.ai/material/week4-computervision/mywork/yolov7/yolov7/detect.py\", line 34, in detect\n",
            "    model = attempt_load(weights, map_location=device)  # load FP32 model\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/charbel/Desktop/stages/inmind.ai/material/week4-computervision/mywork/yolov7/yolov7/models/experimental.py\", line 253, in attempt_load\n",
            "    model.append(ckpt['ema' if ckpt.get('ema') else 'model'].float().fuse().eval())  # FP32 model\n",
            "                               ^^^^^^^^\n",
            "  File \"/home/charbel/.local/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1709, in __getattr__\n",
            "    raise AttributeError(f\"'{type(self).__name__}' object has no attribute '{name}'\")\n",
            "AttributeError: 'Model' object has no attribute 'get'\n"
          ]
        }
      ],
      "source": [
        "# Run evaluation\n",
        "!python detect.py --weights runs/train/yolov7/weights/init.pt --conf 0.1 --source ../yolov7_data/test/images/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 964
        },
        "id": "6AGhNOSSHY4_",
        "outputId": "b0e7593f-5c5b-4807-82ab-57ffc65a8ca2"
      },
      "outputs": [],
      "source": [
        "#display inference on ALL test images\n",
        "\n",
        "import glob\n",
        "from IPython.display import Image, display\n",
        "\n",
        "i = 0\n",
        "limit = 10000 # max images to print\n",
        "for imageName in glob.glob('/content/yolov7/runs/detect/exp/*.jpg'): #assuming JPG\n",
        "    if i < limit:\n",
        "      display(Image(filename=imageName))\n",
        "      print(\"\\n\")\n",
        "    i = i + 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CMOfi7eLJCT3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMumI7a2JDAN"
      },
      "source": [
        "# Reparameterize for Inference\n",
        "\n",
        "https://github.com/WongKinYiu/yolov7/blob/main/tools/reparameterization.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jn4kCtgKiGO"
      },
      "source": [
        "# OPTIONAL: Deployment\n",
        "\n",
        "To deploy, you'll need to export your weights and save them to use later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wWOok8abrCsL"
      },
      "outputs": [],
      "source": [
        "# optional, zip to download weights and results locally\n",
        "\n",
        "!zip -r export.zip runs/detect\n",
        "!zip -r export.zip runs/train/exp/weights/best.pt\n",
        "!zip export.zip runs/train/exp/*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f41PvE5gKhYw"
      },
      "source": [
        "# OPTIONAL: Active Learning Example\n",
        "\n",
        "Once our first training run is complete, we should use our model to help identify which images are most problematic in order to investigate, annotate, and improve our dataset (and, therefore, model).\n",
        "\n",
        "To do that, we can execute code that automatically uploads images back to our hosted dataset if the image is a specific class or below a given confidence threshold.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mcINqQS7Kt3-"
      },
      "outputs": [],
      "source": [
        "# # setup access to your workspace\n",
        "# rf = Roboflow(api_key=\"YOUR_API_KEY\")                               # used above to load data\n",
        "# inference_project =  rf.workspace().project(\"YOUR_PROJECT_NAME\")    # used above to load data\n",
        "# model = inference_project.version(1).model\n",
        "\n",
        "# upload_project = rf.workspace().project(\"YOUR_PROJECT_NAME\")\n",
        "\n",
        "# print(\"inference reference point: \", inference_project)\n",
        "# print(\"upload destination: \", upload_project)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cEl1NVE3LSD_"
      },
      "outputs": [],
      "source": [
        "# # example upload: if prediction is below a given confidence threshold, upload it\n",
        "\n",
        "# confidence_interval = [10,70]                                   # [lower_bound_percent, upper_bound_percent]\n",
        "\n",
        "# for prediction in predictions:                                  # predictions list to loop through\n",
        "#   if(prediction['confidence'] * 100 >= confidence_interval[0] and\n",
        "#           prediction['confidence'] * 100 <= confidence_interval[1]):\n",
        "\n",
        "#           # upload on success!\n",
        "#           print(' >> image uploaded!')\n",
        "#           upload_project.upload(image, num_retry_uploads=3)     # upload image in question"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVpCFeU-K4gb"
      },
      "source": [
        "# Next steps\n",
        "\n",
        "Congratulations, you've trained a custom YOLOv7 model! Next, start thinking about deploying and [building an MLOps pipeline](https://docs.roboflow.com) so your model gets better the more data it sees in the wild."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
