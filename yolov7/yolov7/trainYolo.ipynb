{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nD-uPyQ_2jiN"
      },
      "outputs": [],
      "source": [
        "# # Download YOLOv7 repository and install requirements\n",
        "# !git clone https://github.com/WongKinYiu/yolov7\n",
        "# %cd yolov7\n",
        "# %pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bUbmy674bhpD"
      },
      "outputs": [],
      "source": [
        "# !wget https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7_training.pt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Yolo augment data internally so no need to augment it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1iqOPKjr22mL"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-08-18 00:02:04.964506: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-08-18 00:02:09.823328: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-08-18 00:02:17.408981: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-08-18 00:02:17.910944: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-08-18 00:02:20.097037: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "YOLOR ðŸš€ f18e862 torch 2.3.1+cu121 CPU\n",
            "\n",
            "Namespace(weights='./runs/train/yolov7/weights/best.pt', cfg='cfg/training/yolov7.yaml', data='./data/data.yaml', hyp='./data/hyp.scratch.p5.yaml', epochs=2, batch_size=8, img_size=[640, 640], rect=False, resume=False, nosave=False, notest=True, noautoanchor=True, evolve=False, bucket='', cache_images=False, image_weights=False, device='', multi_scale=False, single_cls=False, adam=False, sync_bn=False, local_rank=-1, workers=8, project='runs/train', entity=None, name='yolov7', exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, upload_dataset=False, bbox_interval=-1, save_period=-1, artifact_alias='latest', freeze=[2], v5_metric=False, world_size=1, global_rank=-1, save_dir='runs/train/yolov72', total_batch_size=8)\n",
            "\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.2, lrf=0.2, momentum=2.0, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.0, warmup_bias_lr=0.05, box=0.1, cls=0.5, cls_pw=1.0, obj=0.9, obj_pw=1.5, iou_t=0.25, anchor_t=3.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.2, scale=0.9, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.7, mosaic=0.8, mixup=0.2, copy_paste=0.0, paste_in=0.1, loss_ota=1\n",
            "\u001b[34m\u001b[1mwandb: \u001b[0mInstall Weights & Biases for YOLOR logging with 'pip install wandb' (recommended)\n",
            "Overriding model.yaml nc=80 with nc=9\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1       928  models.common.Conv                      [3, 32, 3, 1]                 \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
            "  5                -2  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
            "  6                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  7                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  8                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  9                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 10  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 11                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
            " 12                -1  1         0  models.common.MP                        []                            \n",
            " 13                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 14                -3  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 16          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 18                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 19                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 20                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 21                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 22                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 23  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 24                -1  1    263168  models.common.Conv                      [512, 512, 1, 1]              \n",
            " 25                -1  1         0  models.common.MP                        []                            \n",
            " 26                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 27                -3  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 28                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 29          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
            " 30                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 31                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 32                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 33                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 34                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 35                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 36  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 37                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n",
            " 38                -1  1         0  models.common.MP                        []                            \n",
            " 39                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 40                -3  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 41                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 42          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
            " 43                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 44                -2  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 45                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 46                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 47                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 48                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 49  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 50                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n",
            " 51                -1  1   7609344  models.common.SPPCSPC                   [1024, 512, 1]                \n",
            " 52                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 53                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 54                37  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 55          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
            " 56                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 57                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 58                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
            " 59                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 60                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 61                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 62[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 63                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 64                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 65                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 66                24  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n",
            " 67          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
            " 68                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 69                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 70                -1  1     73856  models.common.Conv                      [128, 64, 3, 1]               \n",
            " 71                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 72                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 73                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 74[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 75                -1  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n",
            " 76                -1  1         0  models.common.MP                        []                            \n",
            " 77                -1  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n",
            " 78                -3  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n",
            " 79                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 80      [-1, -3, 63]  1         0  models.common.Concat                    [1]                           \n",
            " 81                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 82                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 83                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
            " 84                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 85                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 86                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 87[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 88                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 89                -1  1         0  models.common.MP                        []                            \n",
            " 90                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
            " 91                -3  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
            " 92                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 93      [-1, -3, 51]  1         0  models.common.Concat                    [1]                           \n",
            " 94                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 95                -2  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 96                -1  1   1180160  models.common.Conv                      [512, 256, 3, 1]              \n",
            " 97                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 98                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 99                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            "100[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            "101                -1  1   1049600  models.common.Conv                      [2048, 512, 1, 1]             \n",
            "102                75  1    328704  models.common.RepConv                   [128, 256, 3, 1]              \n",
            "103                88  1   1312768  models.common.RepConv                   [256, 512, 3, 1]              \n",
            "104               101  1   5246976  models.common.RepConv                   [512, 1024, 3, 1]             \n",
            "105   [102, 103, 104]  1     77308  models.yolo.IDetect                     [9, [[12, 16, 19, 36, 40, 28], [36, 75, 76, 55, 72, 146], [142, 110, 192, 243, 459, 401]], [256, 512, 1024]]\n",
            "/home/charbel/.local/lib/python3.11/site-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 415 layers, 37239708 parameters, 37239708 gradients, 105.3 GFLOPS\n",
            "\n",
            "Transferred 564/566 items from ./runs/train/yolov7/weights/best.pt\n",
            "freezing model.0.conv.weight\n",
            "freezing model.0.bn.weight\n",
            "freezing model.0.bn.bias\n",
            "freezing model.1.conv.weight\n",
            "freezing model.1.bn.weight\n",
            "freezing model.1.bn.bias\n",
            "Scaled weight_decay = 0.0005\n",
            "Optimizer groups: 95 .bias, 95 conv.weight, 98 other\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '../yolov7_data/train/labels.cache' images and labels... 700 fou\u001b[0m\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '../yolov7_data/val/labels.cache' images and labels... 200 found, \u001b[0m\n",
            "Image sizes 640 train, 640 test\n",
            "Using 8 dataloader workers\n",
            "Logging results to runs/train/yolov72\n",
            "Starting training for 2 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       0/1        0G    0.1006   0.08659   0.03552    0.2227      1052       640"
          ]
        }
      ],
      "source": [
        "!python ./train.py --batch 8 --epochs 2 --data ./data/data.yaml --weights './runs/train/yolov7/weights/best.pt' --name yolov7 --img 640 640 --cf cfg/training/yolov7.yaml --hyp ./data/hyp.scratch.p5.yaml --noautoanchor --freeze 2 --notest\n",
        "## Training with diffrent hyperparameters\n",
        "# !python ./train.py --batch 8 --epochs 4 --data ./data/data.yaml --weights './runs/train/yolov7/weights/best.pt' --name yolov7 --img 640 640 --cf cfg/training/yolov7.yaml --hyp ./data/hyp.scratch.p6.yaml --notest --noautoanchor --freeze 2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Namespace(weights=['./runs/train/yolov7/weights/best.pt'], data='./data/data.yaml', batch_size=4, img_size=640, conf_thres=0.2, iou_thres=0.65, task='val', device='', single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project='runs/test', name='yolov7', exist_ok=False, no_trace=False, v5_metric=False)\n",
            "YOLOR ðŸš€ f18e862 torch 2.3.1+cu121 CPU\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "IDetect.fuse\n",
            "/home/charbel/.local/lib/python3.11/site-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 314 layers, 36524924 parameters, 6194944 gradients, 103.3 GFLOPS\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '../yolov7_data/val/labels.cache' images and labels... 200 found, \u001b[0m\n",
            "               Class      Images      Labels           P           R      mAP@.5\n",
            "                 all         200       19857       0.239       0.129      0.0627      0.0123\n",
            "            forklift         200         518        0.43       0.378       0.239       0.046\n",
            "                rack         200        1593        0.52      0.0414      0.0307     0.00848\n",
            "               crate         200        5295       0.206       0.216      0.0699      0.0134\n",
            "               floor         200         174       0.273      0.0172     0.00607     0.00147\n",
            "             railing         200         682           0           0           0           0\n",
            "              pallet         200        6475       0.269       0.139      0.0468     0.00778\n",
            "            stillage         200        1164       0.197      0.0636      0.0135     0.00372\n",
            "               iwhub         200         872           0           0           0           0\n",
            "               dolly         200        3084       0.252       0.308       0.159      0.0296\n",
            "Speed: 1163.6/1.2/1164.8 ms inference/NMS/total per 640x640 image at batch-size 4\n",
            "Results saved to runs/test/yolov7\n"
          ]
        }
      ],
      "source": [
        "!python ./test.py --conf-thres 0.2 --batch-size 4 --data ./data/data.yaml --weights './runs/train/yolov7/weights/best.pt' --name yolov7 --img-size 640"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0W0MpUaTCJro"
      },
      "source": [
        "# Detection over a folder of images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "N4cfnLtTCIce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Namespace(weights=['./runs/train/yolov7/weights/best.pt'], source='../yolov7_data/test/images', img_size=640, conf_thres=0.1, iou_thres=0.45, device='', view_img=False, save_txt=False, save_conf=False, nosave=False, classes=None, agnostic_nms=False, augment=False, update=False, project='runs/detect', name='exp', exist_ok=False, no_trace=False)\n",
            "YOLOR ðŸš€ f18e862 torch 2.3.1+cu121 CPU\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "IDetect.fuse\n",
            "/home/charbel/.local/lib/python3.11/site-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 314 layers, 36524924 parameters, 6194944 gradients, 103.3 GFLOPS\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "4 forklifts, 4 racks, 36 crates, 9 pallets, 7 stillages, 11 dollys, Done. (1165.1ms) Inference, (1.5ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0017.png\n",
            "3 forklifts, 9 racks, 86 crates, 2 floors, 16 pallets, 7 stillages, 18 dollys, Done. (1012.4ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0032.png\n",
            "2 forklifts, 4 racks, 17 crates, 1 floor, 9 pallets, 3 stillages, 15 dollys, Done. (1043.2ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0047.png\n",
            "6 forklifts, 4 racks, 15 crates, 1 floor, 9 pallets, 11 stillages, 12 dollys, Done. (1142.5ms) Inference, (0.9ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0049.png\n",
            "3 forklifts, 8 racks, 67 crates, 1 floor, 50 pallets, 12 stillages, 45 dollys, Done. (983.3ms) Inference, (1.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0052.png\n",
            "3 forklifts, 11 racks, 21 crates, 1 floor, 13 pallets, 4 stillages, 16 dollys, Done. (845.3ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0061.png\n",
            "5 forklifts, 6 racks, 61 crates, 1 floor, 33 pallets, 11 stillages, 29 dollys, Done. (1156.3ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0086.png\n",
            "5 forklifts, 2 stillages, Done. (988.7ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0107.png\n",
            "3 forklifts, 1 rack, 23 crates, 1 floor, 26 pallets, 9 stillages, 20 dollys, Done. (1003.1ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0115.png\n",
            "7 forklifts, 10 crates, 1 floor, 53 pallets, 8 stillages, 26 dollys, Done. (1147.8ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0117.png\n",
            "7 racks, 24 crates, 1 floor, Done. (1094.2ms) Inference, (0.9ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0126.png\n",
            "3 forklifts, 6 racks, 41 crates, 1 floor, 29 pallets, 7 stillages, 64 dollys, Done. (1099.4ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0133.png\n",
            "7 forklifts, 4 racks, 29 crates, 1 floor, 44 pallets, 9 stillages, 60 dollys, Done. (1060.2ms) Inference, (1.9ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0152.png\n",
            "4 forklifts, 3 racks, 13 crates, 27 pallets, 5 stillages, 24 dollys, Done. (1194.9ms) Inference, (1.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0162.png\n",
            "4 forklifts, 13 racks, 19 crates, 2 floors, 24 pallets, 9 stillages, 27 dollys, Done. (1227.6ms) Inference, (1.9ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0173.png\n",
            "4 forklifts, 6 racks, 9 crates, 1 floor, 34 pallets, 9 stillages, 35 dollys, Done. (1104.5ms) Inference, (2.9ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0178.png\n",
            "6 forklifts, 2 racks, 11 crates, 1 floor, 11 pallets, 6 stillages, 16 dollys, Done. (1037.8ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0180.png\n",
            "6 forklifts, 4 racks, 7 crates, 1 floor, 12 pallets, 16 stillages, 37 dollys, Done. (1126.9ms) Inference, (0.9ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0181.png\n",
            "2 forklifts, 16 crates, 2 floors, 13 pallets, 5 stillages, 6 dollys, Done. (1165.3ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0184.png\n",
            "3 forklifts, 2 racks, 8 crates, 5 pallets, 6 stillages, 19 dollys, Done. (1076.3ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0186.png\n",
            "4 forklifts, 1 rack, 4 crates, 8 pallets, 11 stillages, 25 dollys, Done. (1171.6ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0189.png\n",
            "3 forklifts, 7 racks, 16 crates, 2 floors, 36 pallets, 10 stillages, 43 dollys, Done. (1011.9ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0207.png\n",
            "9 forklifts, 9 racks, 17 crates, 1 floor, 9 pallets, 12 stillages, 15 dollys, Done. (1035.5ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0217.png\n",
            "6 forklifts, 8 racks, 67 crates, 1 floor, 29 pallets, 17 stillages, 54 dollys, Done. (1301.5ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0226.png\n",
            "2 forklifts, 1 crate, 16 pallets, 5 stillages, 7 dollys, Done. (1076.7ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0227.png\n",
            "1 rack, 11 crates, 4 pallets, 5 dollys, Done. (1260.8ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0231.png\n",
            "3 forklifts, 2 racks, 4 crates, 19 stillages, 19 dollys, Done. (926.1ms) Inference, (1.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0238.png\n",
            "4 forklifts, 4 racks, 4 crates, 14 pallets, 7 stillages, 25 dollys, Done. (1291.3ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0243.png\n",
            "1 forklift, 8 racks, 36 crates, 1 floor, 44 pallets, 13 stillages, 72 dollys, Done. (1015.2ms) Inference, (1.5ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0270.png\n",
            "5 forklifts, 8 racks, 70 crates, 1 floor, 44 pallets, 11 stillages, 54 dollys, Done. (1360.7ms) Inference, (1.6ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0314.png\n",
            "Done. (1183.9ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0346.png\n",
            "1 forklift, 1 rack, 9 crates, 1 floor, 57 pallets, 2 stillages, 21 dollys, Done. (1336.9ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0356.png\n",
            "5 forklifts, 8 racks, 29 crates, 2 floors, 26 pallets, 6 stillages, 28 dollys, Done. (1452.1ms) Inference, (1.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0360.png\n",
            "2 forklifts, 9 racks, 77 crates, 8 pallets, 2 stillages, 13 dollys, Done. (1310.6ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0377.png\n",
            "4 forklifts, 5 racks, 36 crates, 1 floor, 54 pallets, 9 stillages, 32 dollys, Done. (980.7ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0409.png\n",
            "Done. (1015.1ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0414.png\n",
            "4 forklifts, 23 pallets, 11 stillages, 15 dollys, Done. (951.7ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0440.png\n",
            "1 forklift, 1 crate, 1 floor, 11 pallets, 1 dolly, Done. (883.8ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0449.png\n",
            "1 forklift, 9 pallets, 1 dolly, Done. (905.4ms) Inference, (0.8ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0465.png\n",
            "5 racks, 58 crates, 1 floor, 15 pallets, 1 stillage, 11 dollys, Done. (1015.4ms) Inference, (1.6ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0470.png\n",
            "4 forklifts, 7 racks, 53 crates, 1 floor, 45 pallets, 7 stillages, 41 dollys, Done. (843.4ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0492.png\n",
            "3 forklifts, 2 stillages, Done. (692.9ms) Inference, (0.9ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0494.png\n",
            "4 forklifts, 1 rack, 4 crates, 24 pallets, 6 stillages, 20 dollys, Done. (708.1ms) Inference, (1.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0498.png\n",
            "5 forklifts, 5 racks, 12 crates, 1 floor, 9 pallets, 10 stillages, 25 dollys, Done. (917.9ms) Inference, (0.9ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0501.png\n",
            "2 forklifts, 7 racks, 11 crates, 11 pallets, 10 stillages, 19 dollys, Done. (688.0ms) Inference, (0.9ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0506.png\n",
            "6 forklifts, 8 racks, 71 crates, 1 floor, 31 pallets, 6 stillages, 37 dollys, Done. (1047.2ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0510.png\n",
            "6 forklifts, 6 racks, 32 crates, 38 pallets, 8 stillages, 54 dollys, Done. (869.3ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0522.png\n",
            "3 forklifts, 10 racks, 55 crates, 1 floor, 41 pallets, 9 stillages, 47 dollys, Done. (738.9ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0534.png\n",
            "7 forklifts, 8 racks, 91 crates, 2 floors, 26 pallets, 7 stillages, 20 dollys, Done. (727.0ms) Inference, (1.7ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0546.png\n",
            "4 forklifts, 1 rack, 7 crates, 1 floor, 7 pallets, 4 stillages, 10 dollys, Done. (808.9ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0556.png\n",
            "3 forklifts, 1 rack, 34 crates, 2 floors, 27 pallets, 9 stillages, 32 dollys, Done. (717.6ms) Inference, (1.5ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0571.png\n",
            "5 forklifts, 7 racks, 69 crates, 1 floor, 27 pallets, 6 stillages, 27 dollys, Done. (841.8ms) Inference, (1.4ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0580.png\n",
            "4 forklifts, 7 racks, 7 crates, 1 floor, 9 pallets, 11 stillages, 20 dollys, Done. (936.2ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0591.png\n",
            "Done. (876.5ms) Inference, (0.7ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0604.png\n",
            "Done. (729.5ms) Inference, (0.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0639.png\n",
            "6 forklifts, 2 racks, 36 crates, 1 floor, 38 pallets, 7 stillages, 23 dollys, Done. (879.8ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0659.png\n",
            "3 forklifts, 8 racks, 20 crates, 1 floor, 40 pallets, 4 stillages, 37 dollys, Done. (884.3ms) Inference, (1.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0673.png\n",
            "2 forklifts, 8 racks, 23 crates, 1 floor, 13 pallets, 7 stillages, 23 dollys, Done. (1047.9ms) Inference, (2.5ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0675.png\n",
            "6 forklifts, 5 racks, 80 crates, 2 floors, 39 pallets, 9 stillages, 75 dollys, Done. (1012.9ms) Inference, (1.5ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0680.png\n",
            "3 forklifts, 7 racks, 3 crates, 1 floor, 9 pallets, 10 stillages, 18 dollys, Done. (934.8ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0682.png\n",
            "7 forklifts, 5 racks, 5 crates, 1 floor, 5 pallets, 10 stillages, 3 dollys, Done. (981.2ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0688.png\n",
            "5 forklifts, 3 racks, 48 crates, 1 floor, 29 pallets, 7 stillages, 21 dollys, Done. (1105.1ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0692.png\n",
            "4 forklifts, 2 racks, 31 crates, 23 pallets, 2 stillages, 31 dollys, Done. (1252.7ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0697.png\n",
            "3 forklifts, 1 rack, 3 pallets, 5 stillages, 2 dollys, Done. (1054.4ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0707.png\n",
            "Done. (1058.9ms) Inference, (0.4ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0732.png\n",
            "4 forklifts, 1 rack, 15 crates, 1 floor, 12 pallets, 5 stillages, 9 dollys, Done. (1052.1ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0751.png\n",
            "4 forklifts, 12 crates, 3 pallets, 2 stillages, 1 dolly, Done. (883.1ms) Inference, (1.7ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0768.png\n",
            "7 forklifts, 11 crates, 1 floor, 15 pallets, 4 stillages, 11 dollys, Done. (1276.4ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0771.png\n",
            "1 forklift, 6 racks, 28 crates, 3 pallets, 9 stillages, 5 dollys, Done. (802.7ms) Inference, (1.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0774.png\n",
            "4 forklifts, 9 racks, 45 crates, 1 floor, 52 pallets, 5 stillages, 43 dollys, Done. (808.1ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0776.png\n",
            "5 forklifts, 12 racks, 29 crates, 1 floor, 47 pallets, 6 stillages, 49 dollys, Done. (1062.8ms) Inference, (1.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0778.png\n",
            "7 forklifts, 6 racks, 41 crates, 1 floor, 47 pallets, 8 stillages, 36 dollys, Done. (1013.8ms) Inference, (2.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0786.png\n",
            "3 forklifts, 8 racks, 11 crates, 1 floor, 6 pallets, 4 stillages, 8 dollys, Done. (1177.0ms) Inference, (1.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0789.png\n",
            "1 forklift, 3 crates, 1 pallet, 1 dolly, Done. (1010.6ms) Inference, (1.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0791.png\n",
            "3 forklifts, 7 racks, 61 crates, 51 pallets, 8 stillages, 49 dollys, Done. (794.8ms) Inference, (1.5ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0798.png\n",
            "2 forklifts, 14 crates, 1 floor, 6 pallets, 2 stillages, Done. (903.9ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0809.png\n",
            "8 forklifts, 11 racks, 39 crates, 1 floor, 41 pallets, 8 stillages, 42 dollys, Done. (866.0ms) Inference, (1.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0810.png\n",
            "2 forklifts, 17 crates, 8 pallets, 1 stillage, 2 dollys, Done. (868.5ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0819.png\n",
            "3 forklifts, 7 racks, 55 crates, 1 floor, 35 pallets, 7 stillages, 36 dollys, Done. (1275.4ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0822.png\n",
            "6 forklifts, 2 racks, 38 crates, 2 floors, 32 pallets, 11 stillages, 53 dollys, Done. (871.9ms) Inference, (1.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0827.png\n",
            "3 forklifts, 4 racks, 3 crates, 4 pallets, 8 stillages, 9 dollys, Done. (1355.6ms) Inference, (1.4ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0845.png\n",
            "4 forklifts, 7 racks, 44 crates, 2 floors, 9 pallets, 7 stillages, 27 dollys, Done. (1707.9ms) Inference, (1.5ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0849.png\n",
            "1 forklift, 5 racks, 30 crates, 1 floor, 11 pallets, 5 stillages, 39 dollys, Done. (1569.9ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0850.png\n",
            "3 forklifts, 6 racks, 52 crates, 1 floor, 20 pallets, 2 stillages, 34 dollys, Done. (1519.0ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0852.png\n",
            "5 racks, 41 crates, 1 floor, 2 pallets, 3 dollys, Done. (1188.5ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0855.png\n",
            "9 forklifts, 6 racks, 39 crates, 2 floors, 10 pallets, 9 stillages, 28 dollys, Done. (1251.9ms) Inference, (1.8ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0860.png\n",
            "4 forklifts, 6 racks, 55 crates, 2 floors, 26 pallets, 4 stillages, 28 dollys, Done. (1506.4ms) Inference, (1.5ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0869.png\n",
            "5 forklifts, 3 racks, 12 crates, 2 floors, 10 pallets, 6 stillages, 32 dollys, Done. (1442.1ms) Inference, (1.4ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0873.png\n",
            "4 forklifts, 2 racks, 45 crates, 1 floor, 16 pallets, 1 stillage, 16 dollys, Done. (1528.9ms) Inference, (2.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0886.png\n",
            "6 forklifts, 3 racks, 54 crates, 1 floor, 18 pallets, 10 stillages, 39 dollys, Done. (1331.6ms) Inference, (2.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0900.png\n",
            "3 forklifts, 5 racks, 45 crates, 1 floor, 42 pallets, 7 stillages, 44 dollys, Done. (1739.8ms) Inference, (1.4ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0907.png\n",
            "6 forklifts, 9 racks, 72 crates, 1 floor, 36 pallets, 8 stillages, 85 dollys, Done. (1670.1ms) Inference, (1.9ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0916.png\n",
            "7 forklifts, 3 racks, 45 crates, 1 floor, 34 pallets, 6 stillages, 26 dollys, Done. (1347.0ms) Inference, (2.4ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0926.png\n",
            "3 forklifts, 4 racks, 61 crates, 28 pallets, 6 stillages, 46 dollys, Done. (1869.5ms) Inference, (1.5ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0946.png\n",
            "5 forklifts, 1 pallet, 4 stillages, 10 dollys, Done. (1709.5ms) Inference, (3.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0947.png\n",
            "7 forklifts, 7 racks, 4 crates, 2 floors, 2 pallets, 5 stillages, Done. (1453.8ms) Inference, (1.9ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0950.png\n",
            "2 forklifts, 5 racks, 55 crates, 1 floor, 28 pallets, 7 stillages, 33 dollys, Done. (1239.6ms) Inference, (1.6ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0967.png\n",
            "Done. (1466.8ms) Inference, (0.4ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0972.png\n",
            "1 forklift, 2 stillages, Done. (1568.5ms) Inference, (1.6ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0983.png\n",
            "5 forklifts, 5 racks, 59 crates, 1 floor, 28 pallets, 10 stillages, 27 dollys, Done. (1352.3ms) Inference, (1.9ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp/rgb_0986.png\n",
            "Done. (123.292s)\n"
          ]
        }
      ],
      "source": [
        "# Run evaluation\n",
        "!python ./detect.py --weights ./runs/train/yolov7/weights/best.pt --conf 0.1 --source ../yolov7_data/test/images\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Export the model to onnx and torchscript"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Namespace(weights='./runs/train/yolov74/weights/best.pt', img_size=[640, 640], batch_size=1, dynamic=False, dynamic_batch=False, grid=False, end2end=True, max_wh=None, topk_all=100, iou_thres=0.45, conf_thres=0.25, device='cpu', simplify=False, include_nms=True, fp16=False, int8=False)\n",
            "YOLOR ðŸš€ f18e862 torch 2.3.1+cu121 CPU\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "IDetect.fuse\n",
            "/home/charbel/.local/lib/python3.11/site-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 314 layers, 36524924 parameters, 6194944 gradients, 103.3 GFLOPS\n",
            "\n",
            "Starting TorchScript export with torch 2.3.1+cu121...\n",
            "TorchScript export success, saved as ./runs/train/yolov74/weights/best.torchscript.pt\n",
            "scikit-learn version 1.5.0 is not supported. Minimum required version: 0.17. Maximum required version: 1.1.2. Disabling scikit-learn conversion API.\n",
            "XGBoost version 2.1.0 has not been tested with coremltools. You may run into unexpected errors. XGBoost 1.4.2 is the most recent version that has been tested.\n",
            "2024-08-17 19:04:47.474382: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-08-17 19:04:47.604674: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-08-17 19:04:47.642282: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-08-17 19:04:47.882059: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-08-17 19:04:49.776397: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "TensorFlow version 2.17.0 has not been tested with coremltools. You may run into unexpected errors. TensorFlow 2.12.0 is the most recent version that has been tested.\n",
            "Torch version 2.3.1+cu121 has not been tested with coremltools. You may run into unexpected errors. Torch 2.2.0 is the most recent version that has been tested.\n",
            "CoreML export failure: Descriptors cannot be created directly.\n",
            "If this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.\n",
            "If you cannot immediately regenerate your protos, some other possible workarounds are:\n",
            " 1. Downgrade the protobuf package to 3.20.x or lower.\n",
            " 2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).\n",
            "\n",
            "More information: https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates\n",
            "\n",
            "Starting TorchScript-Lite export with torch 2.3.1+cu121...\n",
            "TorchScript-Lite export success, saved as ./runs/train/yolov74/weights/best.torchscript.ptl\n",
            "\n",
            "Starting ONNX export with onnx 1.16.2...\n",
            "/home/charbel/Desktop/stages/inmind.ai/material/week4-computervision/mywork/yolov7/yolov7/models/yolo.py:582: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if augment:\n",
            "/home/charbel/Desktop/stages/inmind.ai/material/week4-computervision/mywork/yolov7/yolov7/models/yolo.py:614: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if profile:\n",
            "/home/charbel/Desktop/stages/inmind.ai/material/week4-computervision/mywork/yolov7/yolov7/models/yolo.py:629: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if profile:\n",
            "ONNX export failure: name 'shapes' is not defined\n",
            "\n",
            "Export complete (35.11s). Visualize with https://github.com/lutzroeder/netron.\n"
          ]
        }
      ],
      "source": [
        "!python ./export.py --weights ./runs/train/yolov74/weights/best.pt --img-size 640 640 --include-nms --end2end"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 964
        },
        "id": "6AGhNOSSHY4_",
        "outputId": "b0e7593f-5c5b-4807-82ab-57ffc65a8ca2"
      },
      "outputs": [],
      "source": [
        "# display inference on ALL test images\n",
        "\n",
        "import glob\n",
        "from IPython.display import Image, display\n",
        "\n",
        "i = 0\n",
        "limit = 10000  # max images to print\n",
        "for imageName in glob.glob(\"./runs/detect/exp/*.png\"):  # assuming JPG\n",
        "    if i < limit:\n",
        "        display(Image(filename=imageName))\n",
        "        print(\"\\n\")\n",
        "    i = i + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-08-17 19:11:05.999834: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-08-17 19:11:06.026634: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-08-17 19:11:06.034237: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-08-17 19:11:06.052606: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-08-17 19:11:07.254011: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\n",
            "NOTE: Using experimental fast data loading logic. To disable, pass\n",
            "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
            "    https://github.com/tensorflow/tensorboard/issues/4784\n",
            "\n",
            "I0817 19:11:12.549631 140714369332800 plugin.py:429] Monitor runs begin\n",
            "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
            "TensorBoard 2.17.1 at http://localhost:6006/ (Press CTRL+C to quit)\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!tensorboard --logdir ./runs/train/yolov7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
